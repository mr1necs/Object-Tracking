# Обнаружение и трекинг объектов с использованием YOLO и OpenCV

Этот проект реализует систему обнаружения и трекинга объектов с использованием YOLO и OpenCV. Система предназначена для обработки видеопотоков или входных данных с камеры в реальном времени, распознавания определённых объектов и отслеживания их траектории. Программа модульная и использует объектно-ориентированные принципы программирования (ООП) для повышения масштабируемости и удобства сопровождения.

## Особенности
- **Обнаружение объектов с использованием YOLO**: Быстрое и точное обнаружение с помощью модели YOLO.
- **Трекинг с ROI (Region of Interest)**: После обнаружения объекта обрабатывается только локализованная область для ускорения.
- **Глобальный поиск**: Если объект потерян, система переключается на поиск по всему кадру.
- **Многопоточность**: Параллельная обработка для эффективного обнаружения по сегментам кадра.
- **Визуализация траектории**: Отслеживание и отображение движения обнаруженных объектов.
- **Гибкость устройства**: Поддержка CPU, CUDA (GPU) и MPS (Apple Silicon).

## Структура файлов
```
project/
│
├── main.py               # Точка входа в приложение
├── model_yolo.py         # Загрузка модели YOLO и выполнение предсказаний
├── video_processor.py    # Захват видео и предварительная обработка
├── object_tracker.py     # Логика трекинга объектов и управление ROI
├── utils.py              # Вспомогательные функции (например, разбор аргументов)
├── yolo11n.pt            # Веса модели для запуска программы (возможно заменить)
└── requirements.txt      # Зависимости
```

## Установка
1. Клонируйте репозиторий:
   ```bash
   git clone https://github.com/your-repo-url/project.git
   cd project
   ```

2. Создайте виртуальное окружение (опционально, но рекомендуется):
   ```bash
   python -m venv venv
   source venv/bin/activate  # На Windows: venv\Scripts\activate
   ```

3. Установите зависимости:
   ```bash
   pip install -r requirements.txt
   ```

4. В репозитории уже находится файл весов модели `yolo11n.pt`. Убедитесь, что он находится в корневой директории проекта.

## Использование
1. Запустите программу:
   ```bash
   python main.py -d cuda -c path/to/video.mp4
   ```

2. Аргументы командной строки:
   - `-d`, `--device`: Укажите устройство обработки (`cpu`, `cuda` или `mps`).
   - `-c`, `--camera`: Путь к видеофайлу (по умолчанию используется веб-камера).
   - `-b`, `--buffer`: Максимальный размер буфера для траектории (по умолчанию: 64).
   - `-t`, `--timeout`: Количество кадров до переключения на поиск по всему кадру (по умолчанию: 30).
   - `-o`, `--overlay`: Размер дополнительной области ROI (по умолчанию: 50 пикселей).

## Как это работает
1. **Обнаружение**: Модель YOLO обрабатывает входной кадр или определённую область интереса (ROI).
2. **Трекинг**: Если объект обнаружен, его траектория отслеживается с использованием структуры deque.
3. **Переключение режимов**:
   - **Локализованная обработка ROI**: После обнаружения объекта обрабатывается только меньшая область вокруг него для экономии вычислительных ресурсов.
   - **Глобальный поиск**: Если объект теряется в течение определённого количества кадров, система возвращается к поиску по всему кадру.
4. **Визуализация**: Траектория и ограничивающий прямоугольник обнаруженного объекта отображаются на видеопотоке.

## Зависимости
- Python 3.8+
- OpenCV
- Ultralytics YOLO
- NumPy

Установите все зависимости с помощью команды:
```bash
pip install -r requirements.txt
```

## Пример
```bash
python main.py -d cuda -c ./sample_video.mp4 -b 64 -t 30 -o 50
```
- Обрабатывает видеофайл `sample_video.mp4`.
- Использует GPU (`cuda`) для предсказаний.
- Отслеживает траекторию с буфером на 64 точки.
- Переключается на поиск по всему кадру после 30 кадров потери объекта.
- Добавляет 50 пикселей вокруг ROI для обработки.

## Вклад
Вы можете форкнуть репозиторий и отправить pull requests. Предложения и улучшения всегда приветствуются.


